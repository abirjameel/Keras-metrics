{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F_measure Scoring function \n",
    "### F_measure scoring function is the harmonic mean of specificity and sensitivity\n",
    "F measure is a function of sensitivity and specificity, sometimes it is quite difficult to find a right model esecially when you are grid searching hyperparameters since the model evaluation keras has to offer is only `accuracy` which does not gives you the best model in terms of specificity and sensitivity, i have come up with a new measure that can be used as model evaluation metric that can be used while during the training to asses a model, and even when grid search is used it will give you the model which has best fmeasre score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def f_measure(y_true, y_pred):\n",
    "    \n",
    "    def specificity(y_true, y_pred):\n",
    "        \"\"\"Compute the confusion matrix for a set of predictions.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred   : predicted values for a batch if samples (must be binary: 0 or 1)\n",
    "        y_true   : correct values for the set of samples used (must be binary: 0 or 1)\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        out : the specificity\n",
    "        \"\"\"\n",
    "        neg_y_true = 1 - y_true\n",
    "        neg_y_pred = 1 - y_pred\n",
    "        fp = K.sum(neg_y_true * y_pred)\n",
    "        tn = K.sum(neg_y_true * neg_y_pred)\n",
    "        \n",
    "        specificity = tn / (tn + fp + K.epsilon())\n",
    "        return specificity\n",
    "    \n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        \n",
    "        Only computes a batch-wise average of recall.\n",
    "        \n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    specificity = specificity(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((specificity * recall)/(specificity + recall + K.epsilon()))\n",
    "\n",
    "def getmodel(activation_fn = 'relu', dropout = 0.5, learning_rate=0.001, input_dim=1200):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation_fn, input_dim=input_dim))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256, activation=activation_fn))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(128, activation=activation_fn))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(64, activation=activation_fn))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(32, activation=activation_fn))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    adam = optimizers.Adam(lr = learning_rate)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = adam, metrics = [f_measure])\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
